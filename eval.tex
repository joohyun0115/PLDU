

\begin{figure}[tb]
  \begin{center}
    \includegraphics[scale=0.65]{graph/aim7.eps}
  \end{center}
  \caption{Scalability of AIM7 multiuser for different method.  The combination
  \deferu with unordered harris list scale well;in contrast, up to 60 core, the
  stock Linux scale linearly, then it  flattens out.}
  \label{fig:aim7}
\end{figure}

\section{Evaluation}



\begin{figure*}[tb]
    \centering
    \begin{subfigure}[b]{0.33\textwidth}
        \includegraphics[height=1.3in]{graph/aim7_cpuutils.eps}
        \caption{AIM7 - 120core}
    \end{subfigure}%
    \begin{subfigure}[b]{0.33\textwidth}
        \includegraphics[height=1.3in]{graph/exim_cpuutils.eps}
        \caption{Exim - 120core}
    \end{subfigure}
    \begin{subfigure}[b]{0.33\textwidth}
        \includegraphics[height=1.3in]{graph/lmbench_cpuutils.eps}
        \caption{Lmbench - 120core}
    \end{subfigure}
        \centering
    \caption{Read-write ratio from 50:50 to 1:99 percent}
    
\end{figure*}


%$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
%Paragraph 1: 무엇을 평가 했는지에 대한 설명 
%$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$

This section answers the following questions experimentally:
\begin{CompactItemize}
\item Does \ldu's design matter for applications?

\item Why does \ldu's scheme scale well?

\item What is acceptable \ldu's update ratios for the update-heavy data
structure?
\end{CompactItemize}

\subsection{Experimental setup}




%$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
%Paragraph 3: 운영체제 및 커널 버전 설명
%$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
\ifkor
We ran the three benchmarks on Linux 4.5.rc6 with stock Linux. 
All experiments were performed on a 120 core machine with 8-socket, 15-core
Intel E7-8870 chips equipped with 792 GB DDR3 DRAM.
\else
We ran the three benchmarks on Linux 4.5.rc6 with stock Linux. 
All experiments were performed on a 120 core machine with 8-socket, 15-core
Intel E7-8870 chips equipped with 792 GB DDR3 DRAM.
\fi

%$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
%Paragraph 1: 벤치 마크 대한 설명
%$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
Fork-intensive applications benefit from the designs described in this
research, so we use well-known three fork-intensive benchmarks:AIM7, a Linux
scalability benchmark;Exim, an email server in MOSBENCH;and Lmbench, a micro
benchmark.
The workloads exhibit the high lock contentions because of the reverse mapping.
Moreover, the AIM7 benchmark is widely used in the Linux community not only for
testing the Linux kernel but also for improving the scalability. 
The Exim is a real world application, but it has scalability bottlenecks caused
by the Linux fork.
Finally, in order to only focus on the fork performance and scalability, we
selected the Lmbench.

%$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
%Paragraph 2-1: Harris Lock free list 구현 내용에 대한 설명 
%$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
In order to compare our \deferu implementation to a concurrent non-blocking
Harris linked list ~\cite{Harris2001Lockfree}, we implemented the
Harris linked list to Linux kernel.
The Harris linked list refers from sysnchrobench~\cite{Gramoli2015Synchrobench}
and ASCYLIB~\cite{David2015ASYNCHRONIZED}, and we slightly convert the
Harris linked list to Linux kernel style.
In addition, we replace the two rmaps data structure to the Harris linked list.
Since the Harris linked list in the synchrobench and the ASCYLIB leaks memory,
we additionally implemented a garbage collector for the Linux kernel
using the Linux's work queues and non-blocking linked list.

%$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
%Paragraph 2: 비교 대상에 대한 설명
%$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
We used four different experiment settings. 
First, we used the stock Linux as the baseline reference. 
Second, we used Harris lock-free list version of the Linux kernel as we
mentioned earlier.
Next, we used the LDU version of the Linux kenrel that used global queue.
Finally, we used the per-core queue version of LDU in the Linux.
Unfortunately, since we could not obtain the detailed implementation of the
Oplog, we excluded the comparison of between \deferu and Oplog in this paper.


%$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
%Paragraph 2-2: Harris list의 수정 내용 설명  - 졸업논문 내용
%$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
\ifkorthesis
In order to further improve performance, we move their ordered list to
unordered list. 
A feature of the Harris linked list is all the nodes are ordered by
their key. 
Zhang~\cite{zhang2013practical} implements a lock-free unordered list
algorithm, whose list is each insert and remove operation appends an
intermediate node at the head of the list;these approach is practically
hard to implement.
Indeed, Linux does not require contains operation because the Linux data
structures such as list, tree and hash table not depended on search key;they
depend on their unique object.
This feature can eliminates the ordered list in Harris linked list.
Therefore, we perform each insert operation appends an intermediate node at
the first node of the list;on the other hand, each remove operation searches
from head to their node.
\fi



\subsection{AIM7}

%$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
%Paragraph 1: AIM7 실험 결과
%$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$


%$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
%Paragraph 1: 워크로드에 대한 설명
%$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
\ifkor
AIM7 forks many processes, each of which concurrently runs. 
We used AIM7-multiuser, which is one of workload in AIM7.
The multiuser workload is composed of various workloads such as disk-file
operations, process creation, virtual memory operations, pipe I/O, and
arithmetic operation.
To minimize IO bottlenecks, the workload was executed with tmpfs filesystems, each
of which is 10 GB.
To increase the number of users during our experiment and show the results at the
peak user numbers, 
we used the crossover.
\else
AIM7 forks many processes, each of which concurrently runs. 
We used AIM7-multiuser, which is one of workload in AIM7.
The multiuser workload is composed of various workloads such as disk-file
operations, process creation, virtual memory operations, pipe I/O, and
arithmetic operation.
To minimize IO bottlenecks, the workload was executed with tmpfs filesystems, each
of which is 10 GB.
To increase the number of users during our experiment and show the results at the
peak user numbers, 
we used the crossover.
\fi

%$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
%Paragraph 2: 실험 결과에 대한 설명
%$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
\ifkor
The results for AIM7-multiuser are shown in Figure~\ref{fig:aim7}, and the
results show the throughput of AIM7-multiuser with four different settings.
Up to 60 core, the stock Linux scales linearly while serialized updates in
Linux kernel become bottlenecks. 
However, up to 120core, unordered harris list and our \deferu scale well because
these workloads can run concurrently updates and can reduce the locking
overheads due to reader-writer semaphores(\code{anon\_vma},
\code{file}).
The combination of \deferu with unordered harris list has best performance and
scalability outperforming stock Linux by 1.7x and unordered harris list by
1.1x.
While the unordered harris list has 19\% idle time(see
Table~\ref{tab:memuse}), stock Linux has 51\% idle time waiting to acquire
both \code{anon\_vma's rwsem} and \code{file's i\_mmap\_rwsem}.
We can notice that although \deferu has 23\% idle time, the throughput is higher than
unordered harris list.
In this benchmark, the ordered harris list has the lowest performance and
scalability because their \code{CAS} fails frequently.
\else
The results for AIM7-multiuser are shown in Figure~\ref{fig:aim7}, and the
results show the throughput of AIM7-multiuser with four different settings.
Up to 60 core, the stock Linux scales linearly while serialized updates in
Linux kernel become bottlenecks. 
However, up to 120core, unordered harris list and our \deferu scale well because
these workloads can run concurrently updates and can reduce the locking
overheads due to reader-writer semaphores(\code{anon\_vma},
\code{file}).
The combination of \deferu with unordered harris list has best performance and
scalability outperforming stock Linux by 1.7x and unordered harris list by
1.1x.
While the unordered harris list has 19\% idle time(see
Table~\ref{tab:memuse}), stock Linux has 51\% idle time waiting to acquire
both \code{anon\_vma's rwsem} and \code{file's i\_mmap\_rwsem}.
We can notice that although \deferu has 23\% idle time, the throughput is higher than
unordered harris list.
In this benchmark, the ordered harris list has the lowest performance and
scalability because their \code{CAS} fails frequently.
\fi

\begin{figure}[tb]
  \begin{center}
    \includegraphics[scale=0.65]{graph/exim.eps}
  \end{center}
  \caption{Scalability of Exim. The stock Linux collapses after 60 core;in
  contrast, both unordered harris list and our \deferu flatten out.}
  \label{fig:exim}
\end{figure}
\subsection{Exim}
%$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
%Paragraph 1:  EXIM 실험 결과
%$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$

\begin{figure}[tb]
  \begin{center}
    \includegraphics[scale=0.65]{graph/lmbench.eps}
  \end{center}
  \caption{Execution time of lmbench's fork micro benchmark. The fork micro
  benchmark drops down for all methods up to 15 core but either flattens out or
  goes up slightly after that. At 15 core, the stock Linux goes up;the others
  flattens out}
  \label{fig:MicroBench}
\end{figure}



%$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
%Paragraph 1: 워크로드에 대한 설명
%$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
\ifkor
To measure the performance of Exim, shown in Figure~\ref{fig:exim}, we
used default value of MOSBENCH to use tmpfs for
spool files, log files, and user mail files.
Clients run on the same machine and each client sends to a different user to
prevent contention on user mail file.
The Exim was bottlenecked by per-directory locks protecting file creation in
the spool directories and by forks performed on different
cores~\cite{SilasBoydWickizer2010LinuxScales48}.
Therefore, although we eliminate the fork problem, the Exim may suffer from
contention on spool directories. 
\else
To measure the performance of Exim, shown in Figure~\ref{fig:exim}, we
used default value of MOSBENCH to use tmpfs for
spool files, log files, and user mail files.
Clients run on the same machine and each client sends to a different user to
prevent contention on user mail file.
The Exim was bottlenecked by per-directory locks protecting file creation in
the spool directories and by forks performed on different
cores~\cite{SilasBoydWickizer2010LinuxScales48}.
Therefore, although we eliminate the fork problem, the Exim may suffer from
contention on spool directories. 
\fi

%$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
%Paragraph 2:실험 결과에 대한 설명
%$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
\ifkor
Results shown in Figure~\ref{fig:exim} show that Exim scales well for all
methods up to 60 core but not for higher core counts.
The stock Linux shows performance degradation for more than 60 core.
Both unordered harris list
and our \deferu do not suffer from performance loss 
because they do not acquire the \code{anon\_vma}
semaphore and \code{i\_mmap} semaphore in fork.
\deferu performs better due to the fact that it uses both update-side
absorbing and lock-less list, outperforming stock Linux by 1.6x and unordered
harris list by 1.1x.
Even though we applied scalable solution, Exim shows limitation on scalability
improvement
since the main bottleneck is per-directory lock contention on spool
directories.
The unordered harris list has 31\% idle time, whereas \deferu has 37\% idle
time due to the their efficient concurrent updates.
\else
Results shown in Figure~\ref{fig:exim} show that Exim scales well for all
methods up to 60 core but not for higher core counts.
The stock Linux shows performance degradation for more than 60 core.
Both unordered harris list
and our \deferu do not suffer from performance loss 
because they do not acquire the \code{anon\_vma}
semaphore and \code{i\_mmap} semaphore in fork.
\deferu performs better due to the fact that it uses both update-side
absorbing and lock-less list, outperforming stock Linux by 1.6x and unordered
harris list by 1.1x.
Even though we applied scalable solution, Exim shows limitation on scalability
improvement
since the main bottleneck is per-directory lock contention on spool
directories.
The unordered harris list has 31\% idle time, whereas \deferu has 37\% idle
time due to the their efficient concurrent updates.
\fi



\begin{figure*}[t!]
    \centering
    \begin{subfigure}[b]{0.33\textwidth}
        \includegraphics[height=1.3in]{graph/ratio_aim7.eps}
        \caption{AIM7 - 120core}
    \end{subfigure}%
    \begin{subfigure}[b]{0.33\textwidth}
        \includegraphics[height=1.3in]{graph/ratio_exim.eps}
        \caption{Exim - 120core}
    \end{subfigure}
    \begin{subfigure}[b]{0.33\textwidth}
        \includegraphics[height=1.3in]{graph/ratio_lmbench.eps}
        \caption{Lmbench - 120core}
    \end{subfigure}
        \centering
    \begin{subfigure}[b]{0.33\textwidth}
        \includegraphics[height=1.3in]{graph/ratio_aim7_core.eps}
        \caption{AIM7 - scalability}
    \end{subfigure}%
    \begin{subfigure}[b]{0.33\textwidth}
        \includegraphics[height=1.3in]{graph/ratio_exim_core.eps}
        \caption{Exim - scalability}
    \end{subfigure}
    \begin{subfigure}[b]{0.33\textwidth}
        \includegraphics[height=1.3in]{graph/ratio_lmbench_core.eps}
        \caption{Lmbench - scalability}
    \end{subfigure}
    \caption{Read-write ratio from 50:50 to 1:99 percent}
    
\end{figure*}

\subsection{Lmbench}
%$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
%Paragraph 1: %워크로드에 대한 설명
%$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$


\ifkor
lmbench has various workloads including process creation workload(fork,
exec, sh -c, exit).
This workload is used to measure the basic process primitives such as creating
a new process, running a different program, and context switching. 
We configured process create workload to enable the parallelism option which
specifies the number of benchmark processes to run in
parallel~\cite{mcvoy1996lmbench}; we used 100 processes.
\else
lmbench has various workloads including process creation workload(fork,
exec, sh -c, exit).
This workload is used to measure the basic process primitives such as creating
a new process, running a different program, and context switching. 
We configured process create workload to enable the parallelism option which
specifies the number of benchmark processes to run in
parallel~\cite{mcvoy1996lmbench}; we used 100 processes.
\fi

%$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
%Paragraph 2: 실험 결과에 대한 설명
%$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
\ifkor
The results for lmbench are shown in Figure~\ref{fig:MicroBench}, 
and the results show the execution times of the fork microbenchmark in lmbench
with four different methods.
%The fork micro benchmark drops down for all methods up to 15 core but either
%flattens out or goes up slightly after that.
Three methods outperform stock Linux by 2.2x at 120 cores;however, before 30
core, two harris list have lower performance due to their execution overheads.
%At 15 core, the stock Linux goes up because of the NUMA effect that accesses
%the remote memory.
%On the other hand, the others including the ordered harris list flattens out
%and then they remain constant.
While stock Linux has 90\% idle time, other methods have approximately 50\%
idle time since stock Linux waits to acquire reverse mapping locks such as
\code{anon\_vma's rwsem} and \code{mapping's i\_mmap\_rwsem}.

\else
The results for lmbench are shown in Figure~\ref{fig:MicroBench}, 
and the results show the execution times of the fork microbenchmark in lmbench
with four different methods.
%The fork micro benchmark drops down for all methods up to 15 core but either
%flattens out or goes up slightly after that.
Three methods outperform stock Linux by 2.2x at 120 cores;however, before 30
core, two harris list have lower performance due to their execution overheads.
%At 15 core, the stock Linux goes up because of the NUMA effect that accesses
%the remote memory.
%On the other hand, the others including the ordered harris list flattens out
%and then they remain constant.
While stock Linux has 90\% idle time, other methods have approximately 50\%
idle time since stock Linux waits to acquire reverse mapping locks such as
\code{anon\_vma's rwsem} and \code{mapping's i\_mmap\_rwsem}.
\fi




\subsection{Updates ratio}



%$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
%Paragraph 2:  실험을 수행한 이유
%$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
\ifkor
LDU는 high update rate operation가지는 update-heavy한 data structure를 위한 방법이다.
즉 linux kernel의 rmap과 같이 read가 간혈적으로 발생하는 data structure를 대상으로 사용될 때 굉장히 높은
scalabilty를 보여준다.
우리는 어느 정도의 update rate을 가진 data structure에 LDU를 적용하면 효율적인지
판단하기 위해, 리눅스의 rmap을 대상으로 log를 적용하는 read operation을 추가하여 성능과 확장성을 비교하는 실험을 하였다. 
보다 범위를 좁혀 구체적인 실험 결과를 보기 위해, anonymous rmap은 ldu를 적용한 버전을 대상으로 실험을 하였고,
file ramp에서 update operation(insert or remove)이 수행할 때 read operation(lock +
synchronize)을 비율에 맞게 추가하여 실험하였다.
\else
%LDU는 high update rate operation가지는 update-heavy한 data structure를 위한 방법이다.
The LDU is a method for update-heavy data structure.
%즉 linux kernel의 rmap과 같이 read가 간혈적으로 발생하는 data structure를 대상으로 사용될 때 굉장히 높은
%scalabilty를 보여준다.
That is, the LDU can show substantial scalability where the data structures are
frequently updates but rarely read because the read operation executes the
synchronize function to apply logs.
That means the read operations can be slower.
%우리는 어느 정도의 update rate을 가진 data structure에 LDU를 적용하면 효율적인지 
%판단하기 위해, 리눅스의 rmap을 대상으로 log를 적용하는 read operation을 추가하여 
%성능과 확장성을 비교하는 실험을 하였다. 
To further evaluate LDU and to understand the effect of read operation, we
perform the additional read operation with respect to the rmap.
%보다 범위를 좁혀 구체적인 실험 결과를 보기 위해, anonymous rmap은 ldu를 적용한 버전을 대상으로 실험을 하였고,
%file ramp에서 update operation(insert or remove)이 수행할 때 read operation(lock +
%synchronize)을 비율에 맞게 추가하여 실험하였다.
The anonymous rmap uses the version of ldu with global queue because we
merely focus on read ratio and then we sequentially increase read (lock and
synchronize) ratios regarding the file rmap.
\fi
%$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
%Paragraph 2: 실험 결과에 대한 설명
%$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
\ifkor
그림 <x-x>의 위의 그래프들은 120코어에서 update rate에 따른 성능을 보여주고 아래 그림은
rmap의 update rate에 따른 확장성을 보여준다. 
AIM7은 EXIM과 Lmbench와 다르게 보다 덜 fork-intensive한 특징을 가지므로, log를 적용하는
read operation 상대적으로 덜 호출된다.
따라서 75프로(3 update operation + 1 read)의 update rate을 가지는 data structure에도 stock
리눅스보다 높은 성능과 확장성을 가진다.
Scalability를 보면 90프로 이상의 update rate를 가질 때는 상당히 높은 scalability을 가지며 
80프로 이상의 update rate를 가질 경우에도 scalability가 약간 떨어지나, stock 리눅스보다는
높은 성능을 가진다. 
\else
%그림 <x-x>의 위의 그래프들은 120코어에서 update rate에 따른 성능을 보여주고 아래 그림은
%rmap의 update rate에 따른 확장성을 보여준다. 
The upper graphs of Figure x-x  shows the performance on 120 core depending
on read rate, and the lower graphs represent the scalability.
%AIM7은 EXIM과 Lmbench와 다르게 보다 덜 fork-intensive한 특징을 가지므로, log를 적용하는
%read operation 상대적으로 덜 호출된다.
Since the AIM7 has less fork-intensive workload feature than other ones, the
read operations are invoked relatively infrequently.
%따라서 75프로(3 update operation + 1 read)의 update rate을 가지는 data structure에도 stock
%리눅스보다 높은 성능을 가진다.
As a result, although the data structure uses 75 percent(3
update, 1 read) update rate, the AIM7 has outstanding performance than stock
Linux.
%Scalability를 보면 90프로 이상의 update rate를 가질 때는 상당히 높은 scalability을 가지며 
%80프로 이상의 update rate를 가질 경우에도 scalability가 약간 떨어지나, stock 리눅스보다는
%높은 성능을 가진다.
The scalability of AIM7 shows that LDU substantially high scalability at the
over the 90 percent update rate, and 80 percent update rates slightly. 
\fi

\ifkor
Exim과 Lmbench 경우에는 AIM7 보다 상당히 높은 fork-intensive한 워크로드 특징을 가진다.
Log를 적용하는 read operation이 상당히 짧은 주기로 호출됨에 따라, AIM7보다 높은 85프로 이상의 update rate를 가질
때 디폴트보다 높은 성능을 가진다.
Lmbench의 scalability의 경우 log를 merge하는 read operation이 호출되는 주기가 짧아짐에 따라, 비록
update rate이 90프로를 가져도 코어 수가 90 core 이상에서 scalability가 떨어지나, stock 리눅스 보다는
높은 성능을 가진다. 
\else
%Exim과 Lmbench 경우에는 AIM7 보다 상당히 높은 fork-intensive한 워크로드 특징을 가진다.
The result of the Exim and the Lmbench shows the more high fork-intensive
workload represents the read operations high effects
%Log를 적용하는 read operation이 상당히 짧은 주기로 호출됨에 따라, AIM7보다 높은 85프로 이상의 update rate를
% 가질 때 디폴트보다 높은 성능을 가진다.

%Lmbench의 scalability의 경우 log를 merge하는 read operation이 호출되는 주기가 짧아짐에 따라, 비록
%update rate이 90프로를 가져도 코어 수가 90 core 이상에서 scalability가 떨어지나, stock 리눅스 보다는
%높은 성능을 가진다. 
\fi

%$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
%$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
%Reference Sentence 1
%$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$



%$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
%Reference Sentence 2:LDU paper
%$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$

%This section answers the following questions experimentally:

%\begin{CompactItemize}
%\item Does \deferu's design matter for applications?

%\item Why does \deferu's scheme scale well?
%\end{CompactItemize}


% AIM7, EXIM, Lmbench



% Dynamic nonblocking and lock-less data strucures(structures that access
% dynamically allocated memory that may also be freed at runtime) must typically
% rely on alternative safe memory recalamation mechanisms[COMMUNICATION of the
% ACM 2013] .

%We implemented the new deferred update algorithm in Linux 3.19.rc4 kernel, and
%our modified Linux is available as open source.
%\deferu's scheme is based on deferred processing, so it needs a garbage
%collector for delayed free.
%In order to implement the garbage collector, we use the lock-less list and a
%periodic timer(1 sec) in the Linux.

%Paragraph 2: 문제점을 해결하기 위해 Harris linked list를 적용
%We compare our \deferu implementation to a concurrent non-blocking Harris
%linked list ~\cite{Harris2001Lockfree};therefore, we implement the Harris
% linked list to Linux kernel.
%The code refers from sysnchrobench~\cite{Gramoli2015Synchrobench} and
%ASCYLIB~\cite{David2015ASYNCHRONIZED}, and we convert their linked list to
%Linux kernel style.
%Because both synchrobench and ASCYLIB leak memory, we implement additional
%garbage collector for the Linux kernel using Linux's work queues and lock-less
%list.

%Paragraph 3: 오브젝트의 특징을 고려한 lock-free list 구현 
%In order to further improve performance, we move their ordered list to
%unordered list. 
%A feature of the Harris linked list is all the nodes are ordered by
%their key. 
%Zhang~\cite{zhang2013practical} implements a lock-free unordered list
%algorithm, whose list is each insert and remove operation appends an
%intermediate node at the head of the list;these approach is practically
%hard to implement.
%Indeed, Linux does not require contains operation because the Linux data
%structures such as list, tree and hash table not depended on search key;they
%depend on their unique object.
%This feature can eliminates the ordered list in Harris linked list.
%Therefore, we perform each insert operation appends an intermediate node at
%the first node of the list;on the other hand, each remove operation searches
%from head to their node.

%Paragraph 4: mapping은 DeferU와 Harris linked 리스트 둘 다 적용, 
%하지만 anon은 Harris Lined list 만 적용과 이유
%To the scalability of fork, the reverse mapping's lock contention should
%be eliminated not only from file reverse mapping but also from anonymous
% reverse mapping.
%The structure of file reverse mapping is simplified relatively to the
%structure of anonymous mapping because the anonymous reverse mapping is
%entangled by their global object(\code{anon\_vma}) and their
%chain(\code{anon\_vma\_chain});therefore, we only apply \deferu to file reverse
%mapping.



%\subsection{Experimental setup}
%Paragraph 1: 벤치 마크 대한 설명
%To evaluate the performance of \deferu, we use well-known
%three benchmarks:AIM7 Linux scalability benchmark, Exim email server in
%MOSBENCH and lmbench.
%We selected these three benchmarks because they are fork-intensive workloads
% and exhibit high reverse mapping lock contentions.
%Moreover, AIM7 benchmark has widely been used in practical area not only for
% testing the Linux but also for improving the scalability. 
%To evaluate \deferu for real world
%applications, we use Exim which is the most popular email server.
%A micro benchmark, Lmbench, has been selected to focus on Linux fork
% operation-intensive fine grained evaluations.
%Finally, we wanted to focus on Linux fork performance and scalability;therefore,
%we selected lmbench, a micro benchmark.

%Paragraph 2: 비교 대상에 대한 설명
%In order to evaluate Linux scalability, we used four different experiment
%settings.
%First, we used the stock Linux as the baseline reference. 
%Second, we used ordered Harris lock-free list while 
%we apply unordered Harris lock-free list for the third setting
%(see section ~\ref{sec:implementation}). 
%Finally, we used combination of unordered Harris lock-free list for anonymous
% mapping and our \deferu for file mapping.
%Since we cannot obtain detailed implementation of Oplog, 
%we could not include comparison between \deferu and Oplog in this paper.
%In fact, Oplog's design is based on per-core processing for update-heavy
%structure, but we cannot acquire their detail implementation;therefore, we
%evaluated these four combination.

%Paragraph 3: 운영체제 및 커널 버전 설명
%We ran the three benchmarks on Linux 3.19.rc4 with stock Linux with 
%the automatic NUMA balancing feature disabled because the
%Harris linked list has the iteration issue~\cite{petrank2013lock}. 
%All experiments were performed on a 120 core machine with 8-socket, 15-core
%Intel E7-8870 chips equipped with 792 GB DDR3 DRAM.

%\subsection{AIM7}
%Figure : AIM7 실험 결과

%\begin{figure}[tb]
%  \begin{center}
%    \includegraphics[scale=0.65]{graph/aim7.eps}
%  \end{center}
%  \caption{Scalability of AIM7 multiuser for different method.  The combination
%  \deferu with unordered harris list scale well;in contrast, up to 60 core, the
%  stock Linux scale linearly, then it  flattens out.}
%  \label{fig:aim7}
%\end{figure}

%Paragraph 1: 워크로드에 대한 설명
%AIM7 forks many processes, each of which concurrently runs. 
%We used AIM7-multiuser, which is one of workload in AIM7.
%The multiuser workload is composed of various workloads such as disk-file
%operations, process creation, virtual memory operations, pipe I/O, and
%arithmetic operation.
%To minimize IO bottlenecks, the workload was executed with tmpfs filesystems,
% each of which is 10 GB.
%To increase the number of users during our experiment and show the results at
% the peak user numbers, 
%we used the crossover.

%Paragraph 2: 실험 결과에 대한 설명
%The results for AIM7-multiuser are shown in Figure~\ref{fig:aim7}, and the
%results show the throughput of AIM7-multiuser with four different settings.
%Up to 60 core, the stock Linux scales linearly while serialized updates in
%Linux kernel become bottlenecks. 
%However, up to 120core, unordered harris list and our \deferu scale well
% because these workloads can run concurrently updates and can reduce the locking
%overheads due to reader-writer semaphores(\code{anon\_vma},
%\code{file}).
%The combination of \deferu with unordered harris list has best performance and
%scalability outperforming stock Linux by 1.7x and unordered harris list by
%1.1x.
%While the unordered harris list has 19\% idle time(see
%Table~\ref{tab:memuse}), stock Linux has 51\% idle time waiting to acquire
%both \code{anon\_vma's rwsem} and \code{file's i\_mmap\_rwsem}.
%We can notice that although \deferu has 23\% idle time, the throughput is
% higher than unordered harris list.
%In this benchmark, the ordered harris list has the lowest performance and
%scalability because their \code{CAS} fails frequently.

%\subsection{Exim}
% EXIM 실험 결과
%\begin{figure}[tb]
%  \begin{center}
%    \includegraphics[scale=0.65]{graph/exim.eps}
%  \end{center}
%  \caption{Scalability of Exim. The stock Linux collapses after 60 core;in
%  contrast, both unordered harris list and our \deferu flatten out.}
%  \label{fig:exim}
%\end{figure}

%\begin{table}
%  \centering
%  \small
%  \begin{tabular}{l r r r } \toprule
%    AIM7 & user & sys & idle \\
%    \midrule
%    Stock(anon, file) & 2487 s & 1993 s & 4647 s(51\%)\\ 
%    H(anon, file) & 1123 s & 3631 s & 2186 s(31\%)\\
%    H-unorder(anon, flie) & 3630 s & 2511 s & 1466 s(19\%)\\
%    H-unorder(anon), L(file) & 3630 s & 1903 s & 1662 s(23\%)\\
%    \bottomrule
%  \end{tabular}
%  \begin{tabular}{l r r r } \toprule
%    EXIM & user & sys & idle \\
%    \midrule
%    Stock(anon, file) & 41 s & 499 s & 1260 s(70\%)\\ 
%    H(anon, file) & 47 s & 628 s & 1124 s(62\%)\\
%    H-unorder(anon, file) & 112 s & 1128 s & 559 s(31\%)\\
%    H-unorder(anon), L(file) & 87 s & 1055 s & 657 s(37\%)\\
%    \bottomrule
%  \end{tabular}
%  \begin{tabular}{l r r r } \toprule
%    lmbench & user & sys & idle \\
%    \midrule
%    Stock(anon, file) & 11 s & 208 s & 2158 s(91\%)\\ 
%    H(anon, file) & 11 s & 312 s & 367 s(53\%)\\
%    H-unorder(anon, file) & 11 s & 292 s & 315 s(51\%)\\
%    H-unorder(anon), L(file) & 12 s & 347 s & 349 s(49\%)\\
%    \bottomrule
%  \end{tabular}

%  \caption{Comparison of user, system and idle time at 120 cores.}
%  \label{tab:memuse}
%\end{table}


%Paragraph 1: 워크로드에 대한 설명
%To measure the performance of Exim, shown in Figure~\ref{fig:exim}, we
%used default value of MOSBENCH to use tmpfs for
%spool files, log files, and user mail files.
%Clients run on the same machine and each client sends to a different user to
%prevent contention on user mail file.
%The Exim was bottlenecked by per-directory locks protecting file creation in
%the spool directories and by forks performed on different
%cores~\cite{SilasBoydWickizer2010LinuxScales48}.
%Therefore, although we eliminate the fork problem, the Exim may suffer from
%contention on spool directories. 

%Paragraph 2:실험 결과에 대한 설명
%Results shown in Figure~\ref{fig:exim} show that Exim scales well for all
%methods up to 60 core but not for higher core counts.
%The stock Linux shows performance degradation for more than 60 core.
%Both unordered harris list
%and our \deferu do not suffer from performance loss 
%because they do not acquire the \code{anon\_vma}
%semaphore and \code{i\_mmap} semaphore in fork.
%\deferu performs better due to the fact that it uses both update-side
%absorbing and lock-less list, outperforming stock Linux by 1.6x and unordered
%harris list by 1.1x.
%Even though we applied scalable solution, Exim shows limitation on scalability
%improvement
%since the main bottleneck is per-directory lock contention on spool
%directories.
%The unordered harris list has 31\% idle time, whereas \deferu has 37\% idle
%time due to the their efficient concurrent updates.

%\subsection{lmbench}
%\begin{figure}[tb]
%  \begin{center}
%    \includegraphics[scale=0.65]{graph/lmbench.eps}
%  \end{center}
%  \caption{Execution time of lmbench's fork micro benchmark. The fork micro
%  benchmark drops down for all methods up to 15 core but either flattens out or
%  goes up slightly after that. At 15 core, the stock Linux goes up;the others
%  flattens out}
%  \label{fig:MicroBench}
%\end{figure}

%Paragraph 1: %워크로드에 대한 설명
%lmbench has various workloads including process creation workload(fork,
%exec, sh -c, exit).
%This workload is used to measure the basic process primitives such as creating
%a new process, running a different program, and context switching. 
%We configured process create workload to enable the parallelism option which
%specifies the number of benchmark processes to run in
%parallel~\cite{mcvoy1996lmbench}; we used 100 processes.

%Paragraph 2: 실험 결과에 대한 설명
%The results for lmbench are shown in Figure~\ref{fig:MicroBench}, 
%and the results show the execution times of the fork microbenchmark in lmbench
%with four different methods.
%The fork micro benchmark drops down for all methods up to 15 core but either
%flattens out or goes up slightly after that.
%Three methods outperform stock Linux by 2.2x at 120 cores;however, before 30
%core, two harris list have lower performance due to their execution overheads.
%At 15 core, the stock Linux goes up because of the NUMA effect that accesses
%the remote memory.
%On the other hand, the others including the ordered harris list flattens out
%and then they remain constant.
%While stock Linux has 90\% idle time, other methods have approximately 50\%
%idle time since stock Linux waits to acquire reverse mapping locks such as
%\code{anon\_vma's rwsem} and \code{mapping's i\_mmap\_rwsem}.
