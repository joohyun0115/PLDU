\section{Introduction} \label{sec:introduction}

%$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
%$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
%Background
%$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
With the increasing core counts, processors are changing from multi-core to
many-core systems.
In many-core systems, parallelism of the operating system kernel has been an
important part for the whole the system parallelism.
If the kernel does not scale, applications depending on the shared
resources provided by the operating system kernel would not scale[].
Among operating systems, the scalable operating system is the Linux kernel
because the kernel community has made it scalable[].
The Linux kernel, however, has some scalability
problems~\cite{SilasBoydWickizer2010LinuxScales48}~\cite{Changwoo2016UMSF}.
One of which is update serizlization due to its update lock
contention;update operations cannot run in
parallel~\cite{mckenney2011parallel}~\cite{Matveev2015RLU}~\cite{Dodds2015SCT}.

%$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
%$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
%Problem general
%$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
In order to solve the update serialization problem, various concurrent update
methods have been proposed~\cite{Arbel2014ConcurrentRCU}~\cite{Matveev2015RLU}.
These methods show different performances depending on their update ratios.
In the case of a high update rates(update-heavy) data structure, the
update serialization problem can pose a scalability bottleneck.
However, log-based algorithms~\cite{Hendler2010FC}~\cite{SilasBoydWickizerPth}
can solve this update serialization problem by reducing cache coherence-related
overheads for update-heavy data structures.
When update operations occur, Log-based algorithm logs the update
operation and applies all operation logs to the data structure
before read operation, so readers can read up to date data structure in a way
similar to CoW(Copy On Write)~\cite{PaulDetailLWN}.

%$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
%$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
%Problem 
%$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
S. Boyd-Wickizer et al. proposed Oplog~\cite{SilasBoydWickizerPth}, where logs
update operations with synchronized timestamp counters solves concurrent
updates and cache communication bottleneck for its update-heavy data structure.
The synchronized-timestamp-counters-based-method obtains outstanding
update-side scalability because it can record its operation logs without
cache communication overhead when it logs per-core memory.
However, the synchronized timestamp counters method may incur timestamp merging
and ordering process .
When core counts increase, resolving logs(merging, absorbing) may require
additional sequential processing, which can limit scalalbility and performance.

%$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
%$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
%Method
%$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
%
To solve the problem of sequential processing due to the synchronized timestamp
counters in shared memory system, we propose a novel lightweight log-based
deferred update method(LDU).
LDU simply removes the operation log that requires timestamp counter at
update time and reuses the garbage log in the log's queue without creating new
log.
Therefore, we can eliminate the synchronized timestamp counter and the cache
communication bottleneck.
We combine log-based concurrent update that is widely used in
the distributed system and the minimal hardware-based synchronization
method(compare and swap, test and set, atomic swap) that is used in shared-memory system.

LDU has not only benefits of log-based algorithms but also additional benefits.
First, log-based algorithms can remove synchronization overhead resulting in
reducing the cache invalidation traffic.
Second, these techniques can be easily applied to other data structures.
In addition, since LDU can eliminate the log before inserting the log's queue,
LDU's log management is efficient.

%$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
%$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
%Result
%$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$

To evaluate our approach, we applied LDU to Linux kernel reverse
page mappings(anonymous page mapping, file page mapping) that have the
problem of fork scalability bottleneck in Linux kernel because of
high update rates global data structure.
In addition, we implemented the LDU in a Linux 4.5.rc4.
We evaluated the performance and scalability using a fork-intensive workload-
AIM7~\cite{AIM7Benchmark}, Exim~\cite{Exim} from MOSBENCH~\cite{MOSBENCH},
Lmbench~\cite{mcvoy1996lmbench}-our design improves throughput and execution
time on 120 core by 1.7x, 1.6x, 2.2x respectively, relative to stock Linux.

%$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
%$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
%Contribution 정리
%$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$

\textbf{Contributions.} Our resesarch makes the following contributions:
\begin{itemize}
\item We have developed a novel lightweight log-based deferred update method,
which can remove operation log that requires timestamp counter and reuses
the garbage log in log's queue;therefore, LDU can solve the Oplog's sequential processing problem due to the synchronized timestamp counters.
\item 
We appiled LDU in Linux kernel to two reverse mapping(anonymous, file) on
practial 120core system to reduce fork scalability bottleneck.
Our design improved throughput and execution time on 120 core by 1.7x ~ 2.2x.
\end{itemize}


%$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
%$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
%Mapping
%$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
The rest of this paper is organized as follows.
Section 2 describes the background and the Linux scalability problem.
Section 3 describes the design of the LDU algorithm and 
Section 4 explains how to apply the LDU to Linux kernel, and
Section 5 shows the results of the experimental evaluation. 
Section 6 describes relatived work with our research.
Finally, section 7 concludes the paper.
