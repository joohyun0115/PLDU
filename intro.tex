\section{Introduction} \label{sec:introduction}

%$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
%$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
%Background
%$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
\ifkor
최근 코어수가 증가하고 있다. 따라서 멀티코어에서 매니코어 환경으로 바뀌고 있다. 
이러한 매니코어 환경에서 리눅스 커널의 확장성에는 문제가 있다[][][]. 
확장성 문제 중 하나는 락 경합 때문에 발생하는 직렬화 문제이다[][].
여러 락 때문에 발생하는 직렬화 문제 중 하나가 update operation이기 때문에 문제가 발생한다[][].
그 이유는 update operation는 여러 thread가 동시에 수행되지 못하기 때문이다.
예를 들어, 리눅스 커널의 프로세스간 공유하는 자료구조인 reverse page maps은 update rate가 높은 구조로 되어
있다[][]. 
따라서 리눅스 커널은 reverse page mapping에 대한 update lock에 때문에 serialize 되어 새로운 프로세스를
생성 하는 과정에서 scalability 문제가 있다[][].
\else

\fi


%$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
%$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
%Problem
%$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
\ifkor
이처럼 update serialization 문제를 해결하기 위해 여러 concurrent updates 방법[][][][][][] 들이 연구되고 있다. 
이러한 concurrent updates 방법들은 워크로드 특성인 update ratio에 따라 많은 성능 차이를 보인다[][].
이 중 리눅스 커널의 reverse page mapping과 같이 high update ratio를 가진 update-heavy한 data
structure일 경우에는, update lock 경합 때문에 발생하는 scalability 문제를 해결하기 위한 여러 방법이 있다.
그 중 하나는 cache coherence traffic을 줄인 log-based 알고리즘[][][]을 사용하는 것이다.
Log-based 알고리즘은 lock을 피하기 위해 update가 발생하면, data structure의 update
operation(insert or remove)을 argument와 함께 저장하고, 주기적 또는 read operation을 수행하기 전에
applies the updates in all the logs to the data structure, so reader can read
up to date data structure. 이것은 마치 CoW(Copy On Write)와 유사한 결과를 얻는다. 

S. Boyd-Wickizer et al. 는 synchronized timestamp counters 기반의 per-core log를 활용하여
update heavy한 자료구조에서의 concurrent updates 문제를 해결하였다.
Synchronized timestamp counters 기반의 per-core log를 활용한 concurrent updates 방법은
update 부분만 고려했을 때, conflict free이므로 굉장히 높은 scalability를 가질 수 있다[]. 
하지만 per-core 기반의 synchronized timestamp counters를 사용한 방법은 결국 timestamp
ordering and merging 작업을 야기한다. 
만약 코어 수가 늘어 날 경우, resolving logs(merging or absorbing) may require
additional sequential processing, which can limit scalalbility and
performance.
Furthermore, because limiting the per-core memory size, OpLog does not work
well for all data structures.
%(OpLog는 각각의 per-core메모리에 저장된 로그의 오브젝트를 해쉬 테이블을 통해 구별한다.)
%(OpLog distinguishs each log's object saving the per-core memory through(via)
% hash table).
\else

\fi



%$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
%$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
%Method
%$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
%
\ifkor
본 논문은 high update rate를 가진 data structure를 위한 새로운 방법인 LDU를 제안한다. 
LDU는 synchronized timestamp counters를 이용함에 따라 생기는 ordering or merging overhead와
workload에 따른 interfaces dependency가 있는 문제를 줄이기 위해, 조금 더 simple하고
lightweight한 방법을 사용하였다.
즉 우리는 update-heavy한 data structure를 위한 새로운 concurrent updates 방법을 제안한다. 
LDU의 철학은 FC 또는 OpLog와 같이 분산 시스템에서 사용하는 log기반의 concurrent updates 방식과 최소한의
shared-memory system의 hardware-based synchronization 기법(예를 들어, compare and
swap, test and set) 이용하여 이 문제를 해결 하였다.
LDU는 per-core 방식이기 때문에 발생하는 interfaces dependency가 있는 문제를 해결하기 위해, log 저장을
global queue를 사용하는 방식인 GLDU와 per-core에 log를 저장하여 global header의 cache
coherece traffic을 줄인 PLDU로 개발하였으며 이것은 서로간 장단점을 가지고 있다.
또한 update-side absorbing과 reuse garbage등 2가지 optimization 기술을 사용하여 삭제 가능한
operation log를 지우고 재활용하는 방법으로 성능 최적화를 수행하였다.

이처럼 synchronized timestamp counters를 제거함과 동시에, cache communication bottleneck 줄인
LDU는 전형적인 log-based 알고리즘의 장점을 모두 가진다.
첫째로, update가 수행하는 시점 즉 로그를 저장하는 순간에는 lock이 필요가 없다. 
따라서 lock 없이 update를 concurrent하게 수행할 수 있다
둘째로, 저장된 update operation log를 corse-grain lock과 함께 하나의 코어에서 수행하기 때문에,
cache 효율성이 높아진다[FC].
셋째로, 기존 여러 데이터 structure에 쉽게 적용할 수 있는 장점이 있다.
마지막으로 저장된 log를 수행하지 전에 optimization 방법을 사용하여 log의 수를 줄 인다.
\else

\fi

%$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
%$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
%Result
%$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$

\ifkor
우리는 위와 같은 장점을 가지는 LDU를 리눅스 커널의 fork scalability 문제를 야기시키는 2가지 reverse page
mapping(anonymous pape mapping[], file page mapping[])에 적용하였다.
또한 We implemented the LDU in a Linux 4.5.rc4 with elemination of lock. 
We evaluated the performance and scalability using a fork-intensive workload-
AIM7[], Exim from MOSBENCH[], lmbench[]-our design improves throughput and
execution time on 120 core by 1.7x, 1.6x, 2.2x respectively, relative to stock Linux.
  
\else

\fi




%$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
%$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
%Contribution 정리
%$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
\ifkor
\noindent
\textbf{Contributions.} This paper makes the following contributions:
\begin{itemize}
\item 우리는 새로운 log-based concurrnet updates 방법인 LDU를 개발하였다. 
LDU는 synchronized timestamp counters를 이용함에 따라 생기는 ordering or merging overhead와
workload에 따른 interfaces dependency가 있는 문제를 줄이기 위해, 조금 더 simple하고
lightweight한 방법과 update-side absorbing과 reuse garbage의 optimization을
사용하여 log-based concurrent updates를 구현하였다.
\item 우리는 LDU을 practical한 manycore system인 intel xeon 120코어 위에 동작하는 리눅스 커널에
적용하여, fork scalability 문제를 해결하였다. 
Fork 관련 벤치마크 성능은 워크로드 특성에 따라 1.6x부터 2.2x까지 개선되었다.
\end{itemize}
\else

\fi





%$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
%$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
%Mapping
%$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
The rest of this paper is organized as follows.
Section 2 summarizes related works and compare our contributions to previous
works. 
Section 3 describes the design of the LDU algorithm and 
Section 4 explains how to apply to Linux kernel.
section 5 explains our implementations in Linux and
Section 6 shows the results of the experimental evaluation. 
Finally, section 7 concludes the paper.

%$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
%$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
% Reference Sentence 1
%$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
%
%






%$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
%Reference Sentence 2:LDU paper
%$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
% Ondemand로 로그를 지워 준다.
%Background
%With the drastic increase of CPU core counts in various high-end
%server systems, achieving performance scalability of operating systems
%running on such many-core systems has been an important issue in research
%communities.
%Linux has been naturally considered as a major target for the scalability
%improvement and a number of accomplishments are published.
%Early results include RCU~\cite{McKenney98} and hazard
%pointer~\cite{MagedMichael04a} to improve scalability for read-most data 
%structures in the Linux kernel. %for relatively low CPU core counts.
%Though the early results show certain level of improvement in scalability,
%it turned out that more significant portion of scalability limitation of
%Linux kernel is due to lock contention in update-heavy global data structures 
%including file reverse mappings and anonymous reverse mappings during
%spawning child processes~\cite{Andi2011adding}~\cite{Tim2013adding}. 
%Such update-heavy data structures cause serialization of the update operations
%leading to severe performance degradation. 

%Scaling operating systems to many-core architectures is one of the most
%important challenges in computing today. 
%One of the scalable operations system is Linux because the Linux kernel
%community has made it scalable.
%For example, read-mostly data structures in the Linux have been achieved
%considerable multi-core scaling by using RCU~\cite{McKenney98} and hazard
%pointer~\cite{MagedMichael04a}.
%However, the Linux kernel suffers from such scalability bottlenecks at high
%core counts.
%The Linux kernel on many-core processors can be
%bottlenecked by contended updates locks where processes share a global data
%structure.
%When a process spawns child process, reverse mapping using shared global
%data structure suffers from updates lock contention.
%Recent research shows how to run a fork in parallel with creating new reverse
%mapping data structure~\cite{SilasBoydWickizerPth}.
%More specifically, in order to perfect scalability of the fork, both the
%file reverse mapping and the anonymous reverse mapping can execute
%update concurrently without lock
%contention~\cite{Andi2011adding}~\cite{Tim2013adding}.

%The fundamental scalability problem of reverse mapping is their serialized
%update because operating systems are serialized at the update operation.

%To solve this problem, an existing approach is to make the update-heavy data
%structures as non-blocking~\cite{Harris2001Lockfree} based on
% \emph{compare-and-swap}(CAS).
%Introducing non-blocking data structures eliminates the update serialization
% problem during process spawning, but incurs additional issues due to
% inter-core communication
%bottlenecks and cache coherence system's write
% serialization~\cite{SilasBoydWickizerPth}.
%To overcome the issues caused by cache coherence system, S. Boyd-Wickizer et
% al. proposed Oplog~\cite{SilasBoydWickizerPth} where logs update operations
% with time stamps and actual updates are performed later when the updated data
% need to be read.
%While Oplog nicely solves the update serialization problem without any cache
% coherence-related overheads, the merging of the update logs recorded in
% multiple per-core data structures considering time stamps further causes
% performance overheads resulting in limited scalability
% improvement~\cite{McKenney2008ParallelProgramming}.

%Therefore, many researches have proposed non-blocking
%algorithms~\cite{Harris2001Lockfree} for concurrent data structure based on
%\emph{compare-and-swap}(CAS);nonetheless, this method may suffer from inter-core
%communication bottleneck, the cache coherence system serializes the
% writes~\cite{SilasBoydWickizerPth}.

%Another a existing solution is using the per-core processing like
%Oplog~\cite{SilasBoydWickizerPth}, which achieves scalability by logging in
%per-core memory.
%In fact, per-core approach may have best performance for the update-heavy data
%structure because of their partitioned data structures, whose updates can
%operate locally.
%The more-expensive reads, however, must merge across the entire per-core
%data;read operations are expensive~\cite{McKenney2008ParallelProgramming}.
%Therefore, their approach may be complex with regard to the read operation.
%This paper attacks this complexity as a result of the per-core processing.
%Even though they have generalized a per-core processing to the Oplog's library, 
%they use intricate optimizations, so their optimizations may be expensive with
%regard to the read operation.
%For example, they use the absorbing updates that removes the cancelable
%operation before the read.
%This operation may need to iterate previous operation log due to searching the
%cancelable operation log.
%Furthermore, reducing the memory use, they maintain per-core memory space.

%Method
%This paper proposes a novel concurrent update method, \deferu, applicable to
% Linux reverse mapping solving the problems 
%mentioned above: the overheads caused by inter-core communication bottlenecks
% and per-core log management with time stamps. 
%Our goal is to make the Linux fork scale to large numbers of cores using
%lightweight deferred processing algorithm.
%The fork scalability requires two challenges in designing a reverse mapping.
%First, this lightweight method should permit the concurrent updates not only to
%reduce the inter-core communication bottleneck but also to eliminate their 
%complexity.
%Second, this lightweight method should apply to Linux reverse mapping, and
%improve the Linux fork scalability.

%The \deferu is similar to Oplog in that it defers the actual update operations
% as late as possible to reduce serialization problems, but it uses a light
% weight global queue with non-blocking synchronization for update logs and
% eliminates time stamps required for per-core log management. 
%In addition, to optimize the log management and minimize the traversal
% overheads during reading, \deferu applies update-side absorbing algorithm based on atomic
%marking and thus efficiently find the operations to be canceled. 
%The evaluation of the proposed \deferu on Linux kernel 3.19.rc4 running on a
% 120 core system reveals that 
%the execution times could be improved by 1.7x, 1.6x, and 2.2x for 
%a fork-intensive workload-
%AIM7~\cite{AIM7Benchmark}, Exim from
%MOSBENCH~\cite{SilasBoydWickizer2010LinuxScales48}, and 
%lmbench~\cite{mcvoy1996lmbench}, respectively.

%Second, it uses a novel update-side absorbing that uses the atomic marking
%method, which allows \deferu to eliminate read-side traversal for finding the
%cancelable operation log;readers can improve performance.

%The proposed approach has the following advantages. 
%First, it can permits the reverse mapping to remove lock contention, so Linux's
%fork scalability has been improved.
%Second, using the lightweight update-side absorbing, \deferu can reduce
%complexity and improve readers performance.
%Finally, while per-core processing uses the time-stamp counter(e.g., RDTSCP,
%RDTSC) that depend on hardware, our method may not depend on hardware.

%We implemented the \deferu in a Linux 3.19.rc4 with modification of lock. 
%We evaluated the performance and scalability using a fork-intensive workload-
%AIM7~\cite{AIM7Benchmark}, Exim from
%MOSBENCH~\cite{SilasBoydWickizer2010LinuxScales48},
%lmbench~\cite{mcvoy1996lmbench}-our design improves throughput and execution
%time on 120 core by 1.7x, 1.6x, 2.2x respectively, relative to stock Linux.

%Mapping
%Paragraph 
%This paper is organized as follows. 
%Section 2 summarizes related works and compare our contributions to previous
%works. 
%Section 3 describes the design of the \deferu algorithm and 
%Section 4 explains how to apply to Linux kernel.
%section 5 explains our implementations in Linux and
%Section 6 shows the results of the experimental evaluation. 
%Finally, section 7 concludes the paper.